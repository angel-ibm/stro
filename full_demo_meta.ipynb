{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system python3 -m pip install pymilvus confluent-kafka astropy scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Init Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is preliminary stuff \n",
    "\n",
    "important PRESTO.CRT and PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = %system echo QUIT | openssl s_client -showcerts -connect watsonxdata:8443 | \\\n",
    "        awk '/-----BEGIN CERTIFICATE-----/ {p=1}; p; /-----END CERTIFICATE-----/ {p=0}' > ./presto.crt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    utility,\n",
    "    MilvusClient\n",
    ")\n",
    "\n",
    "from astropy.io import fits\n",
    "from skimage.transform import resize\n",
    "\n",
    "def connect_to_milvus() :\n",
    "    \n",
    "    host         = 'eu-de.services.cloud.techzone.ibm.com'\n",
    "    port         = 25782        # <----------- write the external Milvus port here. You get this in your reservation\n",
    "    user         = 'ibmlhadmin'\n",
    "    key          = 'password'\n",
    "    server_pem_path = 'presto.crt'\n",
    "    connections.connect(alias='default',\n",
    "                       host=host,\n",
    "                       port=port,\n",
    "                       user=user,\n",
    "                       password=key,\n",
    "                       server_pem_path=server_pem_path,\n",
    "                       server_name='watsonxdata',\n",
    "                       secure=True)  \n",
    "\n",
    "def create_collection():\n",
    "    \n",
    "    utility.drop_collection(\"image_embeddings\")\n",
    "    \n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"file_path\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=16600),\n",
    "        FieldSchema(name=\"image_width\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"image_height\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"image_utz\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_name\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_ra\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_dec\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_alt\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_az\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"camera_focus\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_temp\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_lat\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_long\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_weather\", dtype=DataType.VARCHAR, max_length=128)\n",
    "\n",
    "    ]\n",
    "    schema = CollectionSchema(fields, \"Embedding of FITS image file\")\n",
    "    \n",
    "    fits_coll = Collection(\"image_embeddings\", schema)\n",
    "\n",
    "    index_params = {\n",
    "            'metric_type':'L2',\n",
    "            'index_type':\"IVF_FLAT\",\n",
    "            'params':{\"nlist\":2048}\n",
    "    }\n",
    "    fits_coll.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "\n",
    "    fits_coll.flush()\n",
    "    \n",
    "    return(fits_coll)\n",
    "\n",
    "def load_fits_file(file_path) :\n",
    "    \n",
    "    with fits.open(file_path) as hdul:\n",
    "        image_header = hdul[0].header\n",
    "        image_data = hdul[0].data\n",
    "        image_resized = resize(image_data, (166, 100), mode='reflect')\n",
    "\n",
    "    return (image_header,image_resized) \n",
    "\n",
    "def generate_embedding(image_data) : \n",
    "    \n",
    "    embedding = image_data.flatten()\n",
    "    embedding = embedding / np.linalg.norm(embedding)  \n",
    "    \n",
    "    return embedding\n",
    "    \n",
    "def insert_embedding(fits_coll, file_path, header, embedding):\n",
    "\n",
    "    image_width = str(header['NAXIS1'])\n",
    "    image_height = str(header['NAXIS2'])\n",
    "    image_utz = header['UT-OBS']\n",
    "    object_name = header['OBJECT']\n",
    "    object_ra = str(header['RA'])\n",
    "    object_dec = str(header['DEC'])\n",
    "    object_alt =str( header['TELALT'])\n",
    "    object_az = str(header['TELAZ'])\n",
    "    camera_focus = str(header['CAMFOCUS'])\n",
    "    local_temp = str(header['TELTEMP'])\n",
    "    local_lat = str(header['LATITUDE'])\n",
    "    local_long = str(header['LONGITUD'])\n",
    "    local_weather = str(header['WEATHER'])\n",
    "\n",
    "    fits_coll.insert([  [file_path], \n",
    "                        [embedding],\n",
    "                        [image_width], \n",
    "                        [image_height], \n",
    "                        [image_utz], \n",
    "                        [object_name], \n",
    "                        [object_ra], \n",
    "                        [object_dec], \n",
    "                        [object_alt],\n",
    "                        [object_az], \n",
    "                        [camera_focus], \n",
    "                        [local_temp], \n",
    "                        [local_lat], \n",
    "                        [local_long], \n",
    "                        [local_weather]   \n",
    "                      ])\n",
    "    fits_coll.load()\n",
    "\n",
    "def initialize_collection():\n",
    "    fits_coll = create_collection()\n",
    "    file_paths = glob.glob(\"./images/m31*.FITS\")\n",
    "    for image_file in sorted(file_paths):\n",
    "        print(\"Inserting file: \", image_file)\n",
    "        image_header, image_data = load_fits_file(image_file)\n",
    "        embedding_vector = generate_embedding(image_data)\n",
    "        insert_embedding(fits_coll, image_file, image_header, embedding_vector)\n",
    "    return fits_coll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the action begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_to_milvus()\n",
    "fits_coll = initialize_collection()\n",
    "connections.disconnect(alias=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Init watsonx.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import prestodb\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "def connect_to_watsonxdata() :\n",
    "\n",
    "    # Connection Parameters\n",
    "    userid     = 'ibmlhadmin'\n",
    "    password   = 'password'\n",
    "    hostname   = 'watsonxdata'\n",
    "    port       = '8443'\n",
    "    catalog    = 'tpch'\n",
    "    schema     = 'tiny'\n",
    "    certfile   = \"/certs/lh-ssl-ts.crt\"\n",
    "\n",
    "    # Connect Statement\n",
    "    try:\n",
    "        wxdconnection = prestodb.dbapi.connect(\n",
    "                host=hostname,\n",
    "                port=port,\n",
    "                user=userid,\n",
    "                catalog=catalog,\n",
    "                schema=schema,\n",
    "                http_scheme='https',\n",
    "                auth=prestodb.auth.BasicAuthentication(userid, password)\n",
    "        )\n",
    "        if (certfile != None):\n",
    "            wxdconnection._http_session.verify = certfile\n",
    "        print(\"Connection successful\")\n",
    "        return wxdconnection\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(repr(e))\n",
    "\n",
    "def create_staging_table(wxdconnection) :\n",
    "\n",
    "    cursor = wxdconnection.cursor()\n",
    "\n",
    "    sql = '''\n",
    "        CREATE SCHEMA IF NOT EXISTS \n",
    "            iceberg_data.fits \n",
    "        WITH (location = 's3a://iceberg-bucket/fits') \n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "    \n",
    "    sql = '''\n",
    "        DROP TABLE IF EXISTS \n",
    "            iceberg_data.fits.\"fits-images\"\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "        \n",
    "    sql = '''\n",
    "         CREATE TABLE \n",
    "            iceberg_data.fits.\"fits-images\" (\n",
    "                filename   VARCHAR,\n",
    "                filebytes  VARCHAR,\n",
    "                image_width VARCHAR,\n",
    "                image_height VARCHAR,\n",
    "                image_utz VARCHAR,\n",
    "                object_name VARCHAR,\n",
    "                object_ra VARCHAR,\n",
    "                object_dec VARCHAR,\n",
    "                object_alt VARCHAR,\n",
    "                object_az VARCHAR,\n",
    "                camera_focus VARCHAR,\n",
    "                local_temp VARCHAR,\n",
    "                local_lat VARCHAR,\n",
    "                local_long VARCHAR,\n",
    "                local_weather VARCHAR\n",
    "            )\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "def insert_file(wxdconnection, image_file):\n",
    "\n",
    "    with open(image_file, 'rb') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    encoded_file_content = base64.b64encode(file_content).decode('utf-8')\n",
    "\n",
    "    with fits.open(image_file) as hdul:\n",
    "        image_header = hdul[0].header\n",
    "\n",
    "        image_width = str(image_header['NAXIS1'])\n",
    "        image_height = str(image_header['NAXIS2'])\n",
    "        image_utz = image_header['UT-OBS']\n",
    "        object_name = image_header['OBJECT']\n",
    "        object_ra = str(image_header['RA'])\n",
    "        object_dec = str(image_header['DEC'])\n",
    "        object_alt =str(image_header['TELALT'])\n",
    "        object_az = str(image_header['TELAZ'])\n",
    "        camera_focus = str(image_header['CAMFOCUS'])\n",
    "        local_temp = str(image_header['TELTEMP'])\n",
    "        local_lat = str(image_header['LATITUDE'])\n",
    "        local_long = str(image_header['LONGITUD'])\n",
    "        local_weather = str(image_header['WEATHER'])\n",
    "\n",
    "    cursor = wxdconnection.cursor()\n",
    "\n",
    "    # I know this is a crime\n",
    "    sql = f'''\n",
    "        INSERT INTO iceberg_data.fits.\"fits-images\" (\n",
    "            filename, \n",
    "            filebytes,\n",
    "            image_width ,\n",
    "            image_height ,\n",
    "            image_utz ,\n",
    "            object_name ,\n",
    "            object_ra ,\n",
    "            object_dec ,\n",
    "            object_alt ,\n",
    "            object_az ,\n",
    "            camera_focus ,\n",
    "            local_temp ,\n",
    "            local_lat ,\n",
    "            local_long ,\n",
    "            local_weather \n",
    "        )\n",
    "        VALUES ( \n",
    "            '{image_file}',\n",
    "            '{encoded_file_content}',\n",
    "            '{image_width}' ,\n",
    "            '{image_height} ',\n",
    "            '{image_utz}' ,\n",
    "            '{object_name}' ,\n",
    "            '{object_ra} ',\n",
    "            '{object_dec}' ,\n",
    "            '{object_alt}' ,\n",
    "            '{object_az} ',\n",
    "            '{camera_focus}' ,\n",
    "            '{local_temp} ',\n",
    "            '{local_lat}' ,\n",
    "            '{local_long}' ,\n",
    "            '{local_weather}'                     \n",
    "        )\n",
    "    '''  \n",
    "\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        wxdconnection.commit() \n",
    "    except Exception as err:\n",
    "        print(f\"Error executing SQL: {repr(err)}\")\n",
    "    finally:\n",
    "        cursor.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the action begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wxdconnection = connect_to_watsonxdata()\n",
    "\n",
    "create_staging_table(wxdconnection)\n",
    "\n",
    "file_paths = glob.glob(\"./images/m31*.FITS\")\n",
    "for image_file in sorted(file_paths):\n",
    "        print(\"Inserting file: \", image_file)\n",
    "        insert_file(wxdconnection,image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Send image to Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import base64\n",
    "\n",
    "from astropy.io import fits\n",
    "from confluent_kafka import Producer, KafkaError\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "BROKER = 'watsonxdata:29092' \n",
    "topic = 'fits-images'  \n",
    "\n",
    "def create_kafka_topic(topic_name, num_partitions=1, replication_factor=1):\n",
    "\n",
    "    admin_client = AdminClient({'bootstrap.servers': BROKER})\n",
    "\n",
    "    existing_topics = admin_client.list_topics(timeout=10).topics\n",
    "\n",
    "    if topic_name in existing_topics:\n",
    "        delete_futures = admin_client.delete_topics([topic_name], operation_timeout=30)\n",
    "        for topic, future in delete_futures.items():\n",
    "            try:\n",
    "                future.result()  \n",
    "                print(f\"Topic '{topic}' has been marked for deletion.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete topic '{topic}': {e}\")\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        timeout = 10\n",
    "        check_interval = 5\n",
    "\n",
    "        while time.time() - start_time < timeout:\n",
    "            \n",
    "            metadata = admin_client.list_topics(timeout=timeout)\n",
    "            \n",
    "            if topic_name not in metadata.topics:\n",
    "                print(f\"Topic '{topic_name}' has been successfully deleted.\")\n",
    "                return\n",
    "            else:\n",
    "                print(f\"Topic '{topic_name}' is still being deleted. Checking again in {check_interval} seconds...\")\n",
    "\n",
    "            time.sleep(check_interval)\n",
    "\n",
    "    topic_list = [NewTopic(topic=topic_name, num_partitions=num_partitions, replication_factor=replication_factor)]\n",
    "\n",
    "    fs = admin_client.create_topics(new_topics=topic_list)\n",
    "\n",
    "    for topic, f in fs.items():\n",
    "        try:\n",
    "            f.result()  \n",
    "            print(f\"Created Kafka topic: {topic}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create topic {topic}: {e}\")\n",
    "\n",
    "def create_kafka_producer():\n",
    "    conf = {\n",
    "        'bootstrap.servers': BROKER,\n",
    "        'client.id': 'fits_image_producer',\n",
    "    }\n",
    "    return Producer(conf)\n",
    "\n",
    "def read_fits_image_as_base64(fits_image_path) :\n",
    "\n",
    "    with open(fits_image_path, 'rb') as file :\n",
    "        file_content = file.read()\n",
    "    \n",
    "    encoded_file_content = base64.b64encode(file_content).decode('utf-8')\n",
    "\n",
    "    with fits.open(fits_image_path) as hdul:\n",
    "        image_header = hdul[0].header\n",
    "\n",
    "    return image_header, encoded_file_content\n",
    "\n",
    "def send_file_image_to_kafka(producer, topic, file, image_base64, header):\n",
    "\n",
    "    image_width = str(header['NAXIS1'])\n",
    "    image_height = str(header['NAXIS2'])\n",
    "    image_utz = header['UT-OBS']\n",
    "    object_name = header['OBJECT']\n",
    "    object_ra = str(header['RA'])\n",
    "    object_dec = str(header['DEC'])\n",
    "    object_alt =str( header['TELALT'])\n",
    "    object_az = str(header['TELAZ'])\n",
    "    camera_focus = str(header['CAMFOCUS'])\n",
    "    local_temp = str(header['TELTEMP'])\n",
    "    local_lat = str(header['LATITUDE'])\n",
    "    local_long = str(header['LONGITUD'])\n",
    "    local_weather = str(header['WEATHER'])\n",
    "\n",
    "    event = {\n",
    "        'file':         file,\n",
    "        'image_width':  image_width,\n",
    "        'image_height': image_height,\n",
    "        'image_utz':    image_utz,\n",
    "        'object_name':  object_name,\n",
    "        'object_ra':    object_ra,\n",
    "        'object_dec':   object_dec,\n",
    "        'object_alt':   object_alt,\n",
    "        'object_az':    object_az,\n",
    "        'camera_focus': camera_focus,\n",
    "        'local_temp':   local_temp,\n",
    "        'local_lat':    local_lat,\n",
    "        'local_long':   local_long,\n",
    "        'local_weather':local_weather,   \n",
    "        'image_data':   image_base64        \n",
    "    }\n",
    "    \n",
    "    producer.produce(topic, key=\"fits_image\", value=json.dumps(event), callback=delivery_report)\n",
    "    producer.flush()\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered to {msg.topic()} [{msg.partition()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this only the first time or if you want to recreate the topic from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_kafka_topic(topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, more action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "producer = create_kafka_producer()\n",
    "\n",
    "file_image_path = './images/m31dot.fits'  \n",
    "image_header, image_base64 = read_fits_image_as_base64(file_image_path)\n",
    "\n",
    "send_file_image_to_kafka(producer, topic, file_image_path, image_base64, image_header)\n",
    "\n",
    "print(f'File sent to Kafka topic \"{topic}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Receive image from Kafka and store it in watsonx.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import base64\n",
    "import prestodb\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "def create_kafka_consumer():\n",
    "    conf = {\n",
    "        'bootstrap.servers': 'watsonxdata:29092',  \n",
    "        'group.id': 'fits_image_group',\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "    return Consumer(conf)\n",
    "\n",
    "def save_base64_fits_image(base64_image, output_fits_path):\n",
    "    \n",
    "    image_bytes = base64.b64decode(base64_image)\n",
    "\n",
    "    with open(output_fits_path, 'wb') as f:\n",
    "        f.write(image_bytes)\n",
    "\n",
    "def connect_to_watsonxdata() :\n",
    "\n",
    "    # Connection Parameters\n",
    "    userid     = 'ibmlhadmin'\n",
    "    password   = 'password'\n",
    "    hostname   = 'watsonxdata'\n",
    "    port       = '8443'\n",
    "    catalog    = 'tpch'\n",
    "    schema     = 'tiny'\n",
    "    certfile   = \"/certs/lh-ssl-ts.crt\"\n",
    "\n",
    "    # Connect Statement\n",
    "    try:\n",
    "        wxdconnection = prestodb.dbapi.connect(\n",
    "                host=hostname,\n",
    "                port=port,\n",
    "                user=userid,\n",
    "                catalog=catalog,\n",
    "                schema=schema,\n",
    "                http_scheme='https',\n",
    "                auth=prestodb.auth.BasicAuthentication(userid, password)\n",
    "        )\n",
    "        if (certfile != None):\n",
    "            wxdconnection._http_session.verify = certfile\n",
    "        print(\"Connection successful\")\n",
    "        return wxdconnection\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(repr(e))\n",
    "\n",
    "\n",
    "def insert_into_watsonxdata(wxdconnection,\n",
    "                            file,\n",
    "                            image_width  ,\n",
    "                            image_height ,\n",
    "                            image_utz    ,\n",
    "                            object_name  ,\n",
    "                            object_ra    ,\n",
    "                            object_dec   ,\n",
    "                            object_alt   ,\n",
    "                            object_az    ,\n",
    "                            camera_focus ,\n",
    "                            local_temp   ,\n",
    "                            local_lat    ,\n",
    "                            local_long   ,\n",
    "                            local_weather,  \n",
    "                            image_base64\n",
    "                            ) :\n",
    "\n",
    "    cursor = wxdconnection.cursor()\n",
    "\n",
    "    sql = '''\n",
    "        drop table if exists iceberg_data.angel.\"fits-images-from-message\"\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "    \n",
    "    sql = '''\n",
    "        create table iceberg_data.angel.\"fits-images-from-message\" (     \n",
    "            file VARCHAR,\n",
    "            image_width VARCHAR,\n",
    "            image_height VARCHAR,\n",
    "            image_utz VARCHAR,\n",
    "            object_name VARCHAR,\n",
    "            object_ra VARCHAR,\n",
    "            object_dec VARCHAR,\n",
    "            object_alt VARCHAR,\n",
    "            object_az VARCHAR,\n",
    "            camera_focus VARCHAR,\n",
    "            local_temp VARCHAR,\n",
    "            local_lat VARCHAR,\n",
    "            local_long VARCHAR,\n",
    "            local_weather VARCHAR,\n",
    "            image_data VARCHAR\n",
    "        )\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "\n",
    "\n",
    "    # I know this is a crime\n",
    "    sql = f'''\n",
    "        INSERT INTO iceberg_data.angel.\"fits-images-from-message\" (\n",
    "            file             , \n",
    "            image_width      ,\n",
    "            image_height     ,\n",
    "            image_utz        ,\n",
    "            object_name      ,\n",
    "            object_ra        ,\n",
    "            object_dec       ,\n",
    "            object_alt       ,\n",
    "            object_az        ,\n",
    "            camera_focus     ,\n",
    "            local_temp       ,\n",
    "            local_lat        ,\n",
    "            local_long       ,\n",
    "            local_weather    ,\n",
    "            image_data\n",
    "        )\n",
    "        VALUES ( \n",
    "            '{file}'          ,\n",
    "            '{image_width}'   ,\n",
    "            '{image_height}'  ,\n",
    "            '{image_utz}'     ,\n",
    "            '{object_name}'   ,\n",
    "            '{object_ra}'     ,\n",
    "            '{object_dec}'    ,\n",
    "            '{object_alt}'    ,\n",
    "            '{object_az}'     ,\n",
    "            '{camera_focus}'  ,\n",
    "            '{local_temp}'    ,\n",
    "            '{local_lat}'     ,\n",
    "            '{local_long}'    ,\n",
    "            '{local_weather}' ,\n",
    "            '{image_base64}'                       \n",
    "        )\n",
    "    \n",
    "    '''  \n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        wxdconnection.commit()\n",
    "    except Exception as err:\n",
    "        print(f\"Error executing SQL: {repr(err)}\")\n",
    "    finally:\n",
    "        cursor.close() \n",
    "\n",
    "    print(f'Inserted: {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic = 'fits-images'   \n",
    "\n",
    "\n",
    "consumer = create_kafka_consumer()\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "\n",
    "duration = 30\n",
    "start_time = time.time()\n",
    "\n",
    "print(f'Waiting \"{duration}\" seconds for messages on topic \"{topic}\"...')\n",
    "\n",
    "try:\n",
    "    while time.time() - start_time < duration:\n",
    "        msg = consumer.poll(1.0)  \n",
    "\n",
    "        if msg is None:\n",
    "            continue \n",
    "\n",
    "        if msg.error():           \n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                print(f\"Reached end of partition for topic {msg.topic()}, partition {msg.partition()}\")\n",
    "            elif msg.error():\n",
    "                print(f\"Error occurred: {msg.error()}\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            event = json.loads(msg.value().decode('utf-8'))\n",
    "            \n",
    "            file         = event.get('file')\n",
    "            image_width  = event.get('image_width')\n",
    "            image_height = event.get('image_height')\n",
    "            image_utz    = event.get('image_utz')\n",
    "            object_name  = event.get('object_name')\n",
    "            object_ra    = event.get('object_ra')\n",
    "            object_dec   = event.get('object_dec')\n",
    "            object_alt   = event.get('object_alt')\n",
    "            object_az    = event.get('object_az')\n",
    "            camera_focus = event.get('camera_focus')\n",
    "            local_temp   = event.get('local_temp')\n",
    "            local_lat    = event.get('local_lat')\n",
    "            local_long   = event.get('local_long')\n",
    "            local_weather= event.get('local_weather')\n",
    "            image_base64 = event.get('image_data')\n",
    "            \n",
    "            print(f'Received message: {file}')\n",
    "\n",
    "            wxdconnection = connect_to_watsonxdata()\n",
    "            insert_into_watsonxdata(wxdconnection, \n",
    "                                    file,\n",
    "                                    image_width  ,\n",
    "                                    image_height ,\n",
    "                                    image_utz    ,\n",
    "                                    object_name  ,\n",
    "                                    object_ra    ,\n",
    "                                    object_dec   ,\n",
    "                                    object_alt   ,\n",
    "                                    object_az    ,\n",
    "                                    camera_focus ,\n",
    "                                    local_temp   ,\n",
    "                                    local_lat    ,\n",
    "                                    local_long   ,\n",
    "                                    local_weather,  \n",
    "                                    image_base64)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down consumer...\")\n",
    "\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read image from watsonx.data and search Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import prestodb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.io import fits\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    utility,\n",
    "    MilvusClient\n",
    ")\n",
    "\n",
    "\n",
    "def connect_to_milvus() :\n",
    "\n",
    "    # This is for Baklarz's image\n",
    "    host         = 'eu-de.services.cloud.techzone.ibm.com'\n",
    "    port         = 25782\n",
    "    user         = 'ibmlhadmin'\n",
    "    key          = 'password'\n",
    "    server_pem_path = 'presto.crt'\n",
    "    connections.connect(alias='default',\n",
    "                       host=host,\n",
    "                       port=port,\n",
    "                       user=user,\n",
    "                       password=key,\n",
    "                       server_pem_path=server_pem_path,\n",
    "                       server_name='watsonxdata',\n",
    "                       secure=True)  \n",
    "\n",
    "    # This is for SaaS\n",
    "    # host         = 'acb3dba1-2c32-4c99-9833-6d060a2e32b4.cqh2jh8d00ae3kp0jmpg.lakehouse.appdomain.cloud'\n",
    "    # port         = 30969\n",
    "    # user         = 'ibmlhapikey'\n",
    "    # key          = 'Xndw8q4VKrLoqM2SB_zwbEuqfyH-9d2zwCyaKFIsEElF'\n",
    "    # connections.connect(         \n",
    "    #     host=host, \n",
    "    #     port=port,\n",
    "    #     user=user,\n",
    "    #     password=key,\n",
    "    #     secure=True,\n",
    "    # )\n",
    "    \n",
    "    print(f\"\\nList connections:\")\n",
    "    print(connections.list_connections())\n",
    "\n",
    "    \n",
    "def load_fits_file(file_path) :\n",
    "    \n",
    "    with fits.open(file_path) as hdul:\n",
    "   \n",
    "        image_data = hdul[0].data\n",
    "        image_resized = resize(image_data, (166, 100), mode='reflect')\n",
    "\n",
    "    return (image_resized ) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_embedding(image_data) : \n",
    "    \n",
    "    embedding = image_data.flatten()\n",
    "    embedding = embedding / np.linalg.norm(embedding)  # Normalizing the embedding\n",
    "    \n",
    "    return embedding\n",
    "    \n",
    "def search_image(search_collection, kafka_data) :\n",
    "\n",
    "    file_contents = base64.b64decode(kafka_data)\n",
    "    fits_file = io.BytesIO(file_contents)\n",
    "    with fits.open(fits_file) as hdul:\n",
    "        hdul.info()\n",
    "        image_data = hdul[0].data\n",
    "\n",
    "    image_resized = resize(image_data, (166, 100), mode='reflect')\n",
    "\n",
    "    embedding_vector = generate_embedding(image_resized)\n",
    "    query_embedding = [embedding_vector]\n",
    "    search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 1000}}\n",
    "    search_collection.load()\n",
    "    results = search_collection.search(\n",
    "        data=query_embedding,\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        limit=3,\n",
    "        output_fields=[\"id\", \"file_path\"],  \n",
    "        expr=None\n",
    "    )\n",
    "\n",
    "    for result in results[0]:\n",
    "        print(f\"Image ID: {result.id}, Image File: {result.file_path}, Difference: {result.distance:.2%}\")\n",
    "\n",
    "\n",
    "def connect_to_watsonxdata() :\n",
    "\n",
    "    # Connection Parameters\n",
    "    userid     = 'ibmlhadmin'\n",
    "    password   = 'password'\n",
    "    hostname   = 'watsonxdata'\n",
    "    port       = '8443'\n",
    "    catalog    = 'tpch'\n",
    "    schema     = 'tiny'\n",
    "    certfile   = \"/certs/lh-ssl-ts.crt\"\n",
    "\n",
    "    # Connect Statement\n",
    "    try:\n",
    "        wxdconnection = prestodb.dbapi.connect(\n",
    "                host=hostname,\n",
    "                port=port,\n",
    "                user=userid,\n",
    "                catalog=catalog,\n",
    "                schema=schema,\n",
    "                http_scheme='https',\n",
    "                auth=prestodb.auth.BasicAuthentication(userid, password)\n",
    "        )\n",
    "        if (certfile != None):\n",
    "            wxdconnection._http_session.verify = certfile\n",
    "        cursor = wxdconnection.cursor()\n",
    "        print(\"Connection successful\")\n",
    "        return wxdconnection\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(repr(e))\n",
    "\n",
    "def get_images_from_watsonxdata(wxdconnection) :\n",
    "\n",
    "    sql = '''\n",
    "    SELECT json_extract_scalar(_message, '$.image_data') AS \"image_data\" \n",
    "    FROM \"kafka\".\"default\".\"fits-images\" \n",
    "    LIMIT 100 \n",
    "    '''\n",
    "    try:\n",
    "        df = pd.read_sql(sql,wxdconnection)\n",
    "        if (len(df) == 0):\n",
    "            print(\"No rows found.\")\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_to_milvus()\n",
    "fits_coll = Collection(\"image_embeddings\")\n",
    "\n",
    "wxdconnection = connect_to_watsonxdata()\n",
    "data_images = get_images_from_watsonxdata(wxdconnection)\n",
    "\n",
    "for index, row in data_images.iterrows():\n",
    "    search_image(fits_coll,row['image_data'])\n",
    "\n",
    "\n",
    "connections.disconnect(alias=\"default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
