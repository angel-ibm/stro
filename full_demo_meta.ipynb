{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%system python3 -m pip install pymilvus confluent-kafka astropy scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Init Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is preliminary stuff \n",
    "\n",
    "important PRESTO.CRT and PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = %system echo QUIT | openssl s_client -showcerts -connect watsonxdata:8443 | \\\n",
    "        awk '/-----BEGIN CERTIFICATE-----/ {p=1}; p; /-----END CERTIFICATE-----/ {p=0}' > ./presto.crt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    utility,\n",
    "    MilvusClient\n",
    ")\n",
    "\n",
    "from astropy.io import fits\n",
    "from skimage.transform import resize\n",
    "\n",
    "def connect_to_milvus() :\n",
    "    \n",
    "    host         = 'eu-de.services.cloud.techzone.ibm.com'\n",
    "    port         = 25782        # <----------- write the external Milvus port here. You get this in your reservation\n",
    "    user         = 'ibmlhadmin'\n",
    "    key          = 'password'\n",
    "    server_pem_path = 'presto.crt'\n",
    "    connections.connect(alias='default',\n",
    "                       host=host,\n",
    "                       port=port,\n",
    "                       user=user,\n",
    "                       password=key,\n",
    "                       server_pem_path=server_pem_path,\n",
    "                       server_name='watsonxdata',\n",
    "                       secure=True)  \n",
    "\n",
    "def create_collection():\n",
    "    \n",
    "    utility.drop_collection(\"image_embeddings\")\n",
    "    \n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"file_path\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=16600),\n",
    "        FieldSchema(name=\"image_width\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"image_height\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"image_utz\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_name\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_ra\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_dec\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_alt\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"object_az\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"camera_focus\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_temp\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_lat\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_long\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"local_weather\", dtype=DataType.VARCHAR, max_length=128)\n",
    "\n",
    "    ]\n",
    "    schema = CollectionSchema(fields, \"Embedding of FITS image file\")\n",
    "    \n",
    "    fits_coll = Collection(\"image_embeddings\", schema)\n",
    "\n",
    "    index_params = {\n",
    "            'metric_type':'L2',\n",
    "            'index_type':\"IVF_FLAT\",\n",
    "            'params':{\"nlist\":2048}\n",
    "    }\n",
    "    fits_coll.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "\n",
    "    fits_coll.flush()\n",
    "    \n",
    "    return(fits_coll)\n",
    "\n",
    "def load_fits_file(file_path) :\n",
    "    \n",
    "    with fits.open(file_path) as hdul:\n",
    "        image_header = hdul[0].header\n",
    "        image_data = hdul[0].data\n",
    "        image_resized = resize(image_data, (166, 100), mode='reflect')\n",
    "\n",
    "    return (image_header,image_resized) \n",
    "\n",
    "def generate_embedding(image_data) : \n",
    "    \n",
    "    embedding = image_data.flatten()\n",
    "    embedding = embedding / np.linalg.norm(embedding)  \n",
    "    \n",
    "    return embedding\n",
    "    \n",
    "def insert_embedding(fits_coll, file_path, header, embedding):\n",
    "\n",
    "    image_width = str(header['NAXIS1'])\n",
    "    image_height = str(header['NAXIS2'])\n",
    "    image_utz = header['UT-OBS']\n",
    "    object_name = header['OBJECT']\n",
    "    object_ra = str(header['RA'])\n",
    "    object_dec = str(header['DEC'])\n",
    "    object_alt =str( header['TELALT'])\n",
    "    object_az = str(header['TELAZ'])\n",
    "    camera_focus = str(header['CAMFOCUS'])\n",
    "    local_temp = str(header['TELTEMP'])\n",
    "    local_lat = str(header['LATITUDE'])\n",
    "    local_long = str(header['LONGITUD'])\n",
    "    local_weather = str(header['WEATHER'])\n",
    "\n",
    "    fits_coll.insert([  [file_path], \n",
    "                        [embedding],\n",
    "                        [image_width], \n",
    "                        [image_height], \n",
    "                        [image_utz], \n",
    "                        [object_name], \n",
    "                        [object_ra], \n",
    "                        [object_dec], \n",
    "                        [object_alt],\n",
    "                        [object_az], \n",
    "                        [camera_focus], \n",
    "                        [local_temp], \n",
    "                        [local_lat], \n",
    "                        [local_long], \n",
    "                        [local_weather]   \n",
    "                      ])\n",
    "    fits_coll.load()\n",
    "\n",
    "def initialize_collection():\n",
    "    fits_coll = create_collection()\n",
    "    file_paths = glob.glob(\"./images/m31*.FITS\")\n",
    "    for image_file in sorted(file_paths):\n",
    "        print(\"Inserting file: \", image_file)\n",
    "        image_header, image_data = load_fits_file(image_file)\n",
    "        embedding_vector = generate_embedding(image_data)\n",
    "        insert_embedding(fits_coll, image_file, image_header, embedding_vector)\n",
    "    return fits_coll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the action begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_to_milvus()\n",
    "fits_coll = initialize_collection()\n",
    "connections.disconnect(alias=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Init watsonx.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import prestodb\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def connect_to_watsonxdata() :\n",
    "\n",
    "    # Connection Parameters\n",
    "    userid     = 'ibmlhadmin'\n",
    "    password   = 'password'\n",
    "    hostname   = 'watsonxdata'\n",
    "    port       = '8443'\n",
    "    catalog    = 'tpch'\n",
    "    schema     = 'tiny'\n",
    "    certfile   = \"/certs/lh-ssl-ts.crt\"\n",
    "\n",
    "    # Connect Statement\n",
    "    try:\n",
    "        wxdconnection = prestodb.dbapi.connect(\n",
    "                host=hostname,\n",
    "                port=port,\n",
    "                user=userid,\n",
    "                catalog=catalog,\n",
    "                schema=schema,\n",
    "                http_scheme='https',\n",
    "                auth=prestodb.auth.BasicAuthentication(userid, password)\n",
    "        )\n",
    "        if (certfile != None):\n",
    "            wxdconnection._http_session.verify = certfile\n",
    "        print(\"Connection successful\")\n",
    "        return wxdconnection\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(repr(e))\n",
    "\n",
    "def create_staging_table(wxdconnection) :\n",
    "\n",
    "    cursor = wxdconnection.cursor()\n",
    "\n",
    "    sql = '''\n",
    "        CREATE SCHEMA IF NOT EXISTS \n",
    "            iceberg_data.fits \n",
    "        WITH (location = 's3a://iceberg-bucket/fits') \n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "    \n",
    "    sql = '''\n",
    "        DROP TABLE IF EXISTS \n",
    "            iceberg_data.fits.\"fits-images\"\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "        \n",
    "    sql = '''\n",
    "        CREATE TABLE \n",
    "            iceberg_data.fits.\"fits-images\" (\n",
    "                filename   VARCHAR,\n",
    "                filebytes  VARCHAR\n",
    "            )\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "def insert_file(wxdconnection, image_file):\n",
    "\n",
    "    with open(image_file, 'rb') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    encoded_file_content = base64.b64encode(file_content).decode('utf-8')\n",
    "\n",
    "    cursor = wxdconnection.cursor()\n",
    "\n",
    "    # I know this is a crime\n",
    "    sql = f'''\n",
    "        INSERT INTO iceberg_data.fits.\"fits-images\" (filename, filebytes)\n",
    "        VALUES ( '{image_file}', '{encoded_file_content}' )\n",
    "    '''  \n",
    "\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        wxdconnection.commit() \n",
    "    except Exception as err:\n",
    "        print(f\"Error executing SQL: {repr(err)}\")\n",
    "    finally:\n",
    "        cursor.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the action begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wxdconnection = connect_to_watsonxdata()\n",
    "\n",
    "create_staging_table(wxdconnection)\n",
    "\n",
    "file_paths = glob.glob(\"./images/m31*.FITS\")\n",
    "for image_file in sorted(file_paths):\n",
    "        print(\"Inserting file: \", image_file)\n",
    "        insert_file(wxdconnection,image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Send image to Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, KafkaError\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "import json\n",
    "import base64\n",
    "\n",
    "BROKER = 'watsonxdata:29092' \n",
    "\n",
    "def create_kafka_topic(topic_name, num_partitions=1, replication_factor=1):\n",
    "\n",
    "    admin_client = AdminClient({'bootstrap.servers': BROKER})\n",
    "    \n",
    "    topic_list = [NewTopic(topic=topic_name, num_partitions=num_partitions, replication_factor=replication_factor)]\n",
    "    \n",
    "    existing_topics = admin_client.list_topics(timeout=10).topics\n",
    "    if topic_name not in existing_topics:\n",
    "        fs = admin_client.create_topics(new_topics=topic_list)\n",
    "        for topic, f in fs.items():\n",
    "            try:\n",
    "                f.result()  \n",
    "                print(f\"Created Kafka topic: {topic}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to create topic {topic}: {e}\")\n",
    "    else:\n",
    "        print(f\"Kafka topic {topic_name} already exists.\")\n",
    "\n",
    "def create_kafka_producer():\n",
    "    conf = {\n",
    "        'bootstrap.servers': BROKER,\n",
    "        'client.id': 'fits_image_producer',\n",
    "    }\n",
    "    return Producer(conf)\n",
    "\n",
    "def read_fits_image_as_base64(fits_image_path) :\n",
    "\n",
    "    with open(fits_image_path, 'rb') as file :\n",
    "        file_content = file.read()\n",
    "    \n",
    "    encoded_file_content = base64.b64encode(file_content).decode('utf-8')\n",
    "\n",
    "    return encoded_file_content\n",
    "\n",
    "def send_file_image_to_kafka(producer, topic, file, image_base64):\n",
    "\n",
    "    event = {\n",
    "        'image_format': 'FITS',\n",
    "        'file': file,\n",
    "        'image_data': image_base64        \n",
    "    }\n",
    "    \n",
    "    producer.produce(topic, key=\"fits_image\", value=json.dumps(event), callback=delivery_report)\n",
    "    producer.flush()\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered to {msg.topic()} [{msg.partition()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, more action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'fits-images'  \n",
    "create_kafka_topic(topic)\n",
    "producer = create_kafka_producer()\n",
    "\n",
    "file_image_path = './images/m31dot.fits'  \n",
    "image_base64 = read_fits_image_as_base64(file_image_path)\n",
    "\n",
    "send_file_image_to_kafka(producer, topic, file_image_path, image_base64)\n",
    "\n",
    "print(f'File sent to Kafka topic \"{topic}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Receive image from Kafka and store it in watsonx.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import prestodb\n",
    "\n",
    "def create_kafka_consumer():\n",
    "    conf = {\n",
    "        'bootstrap.servers': 'watsonxdata:29092',  \n",
    "        'group.id': 'fits_image_group',\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "    return Consumer(conf)\n",
    "\n",
    "def save_base64_fits_image(base64_image, output_fits_path):\n",
    "    \n",
    "    image_bytes = base64.b64decode(base64_image)\n",
    "\n",
    "    with open(output_fits_path, 'wb') as f:\n",
    "        f.write(image_bytes)\n",
    "\n",
    "def connect_to_watsonxdata() :\n",
    "\n",
    "    # Connection Parameters\n",
    "    userid     = 'ibmlhadmin'\n",
    "    password   = 'password'\n",
    "    hostname   = 'watsonxdata'\n",
    "    port       = '8443'\n",
    "    catalog    = 'tpch'\n",
    "    schema     = 'tiny'\n",
    "    certfile   = \"/certs/lh-ssl-ts.crt\"\n",
    "\n",
    "    # Connect Statement\n",
    "    try:\n",
    "        wxdconnection = prestodb.dbapi.connect(\n",
    "                host=hostname,\n",
    "                port=port,\n",
    "                user=userid,\n",
    "                catalog=catalog,\n",
    "                schema=schema,\n",
    "                http_scheme='https',\n",
    "                auth=prestodb.auth.BasicAuthentication(userid, password)\n",
    "        )\n",
    "        if (certfile != None):\n",
    "            wxdconnection._http_session.verify = certfile\n",
    "        print(\"Connection successful\")\n",
    "        return wxdconnection\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(repr(e))\n",
    "\n",
    "\n",
    "def insert_into_watsonxdata(wxdconnection, image_format, file, image_base64) :\n",
    "\n",
    "    cursor = wxdconnection.cursor()\n",
    "\n",
    "    sql = '''\n",
    "        drop table if exists iceberg_data.angel.\"fits-images-from-message\"\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "    \n",
    "    sql = '''\n",
    "        create table iceberg_data.angel.\"fits-images-from-message\" (     \n",
    "            \"image_format\" varchar,\n",
    "            \"file\" varchar,\n",
    "            \"image_data\" varchar\n",
    "        )\n",
    "    '''\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except Exception as err:\n",
    "        print(repr(err))\n",
    "\n",
    "\n",
    "    # I know this is a crime\n",
    "    sql = f'''\n",
    "        INSERT INTO iceberg_data.angel.\"fits-images-from-message\" (image_format, file, image_data)\n",
    "        VALUES ( '{image_format}', '{file}','{image_base64}' )\n",
    "    '''  \n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        wxdconnection.commit()\n",
    "    except Exception as err:\n",
    "        print(f\"Error executing SQL: {repr(err)}\")\n",
    "    finally:\n",
    "        cursor.close() \n",
    "\n",
    "    print(f'Inserted: {image_format} {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic = 'fits-images'  \n",
    "output_fits_path = 'received_image.fits'  \n",
    "\n",
    "\n",
    "consumer = create_kafka_consumer()\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "print(f'Waiting for messages on topic \"{topic}\"...')\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)  \n",
    "\n",
    "        if msg is None:\n",
    "            continue \n",
    "\n",
    "        if msg.error():           \n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                print(f\"Reached end of partition for topic {msg.topic()}, partition {msg.partition()}\")\n",
    "            elif msg.error():\n",
    "                print(f\"Error occurred: {msg.error()}\")\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            event = json.loads(msg.value().decode('utf-8'))\n",
    "            image_format = event.get('image_format')\n",
    "            file = event.get('file')\n",
    "            image_base64 = event.get('image_data')\n",
    "            \n",
    "            print(f'Received message: {file}, format: {image_format}')\n",
    "\n",
    "            if image_format == 'FITS' and image_base64:\n",
    "                # Save the image to a FITS file\n",
    "                # save_base64_fits_image(image_base64, output_fits_path)\n",
    "                # print(f'FITS image saved to \"{output_fits_path}\".')\n",
    "\n",
    "                wxdconnection = connect_to_watsonxdata()\n",
    "                insert_into_watsonxdata(wxdconnection, image_format, file, image_base64)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down consumer...\")\n",
    "\n",
    "finally:\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read image from watsonx.data and search Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "import prestodb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.io import fits\n",
    "from skimage.transform import resize\n",
    "\n",
    "from pymilvus import(\n",
    "    Milvus,\n",
    "    IndexType,\n",
    "    Status,\n",
    "    connections,\n",
    "    FieldSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    utility,\n",
    "    MilvusClient\n",
    ")\n",
    "\n",
    "\n",
    "def connect_to_milvus() :\n",
    "\n",
    "    # This is for Baklarz's image\n",
    "    host         = 'eu-de.services.cloud.techzone.ibm.com'\n",
    "    port         = 25782\n",
    "    user         = 'ibmlhadmin'\n",
    "    key          = 'password'\n",
    "    server_pem_path = 'presto.crt'\n",
    "    connections.connect(alias='default',\n",
    "                       host=host,\n",
    "                       port=port,\n",
    "                       user=user,\n",
    "                       password=key,\n",
    "                       server_pem_path=server_pem_path,\n",
    "                       server_name='watsonxdata',\n",
    "                       secure=True)  \n",
    "\n",
    "    # This is for SaaS\n",
    "    # host         = 'acb3dba1-2c32-4c99-9833-6d060a2e32b4.cqh2jh8d00ae3kp0jmpg.lakehouse.appdomain.cloud'\n",
    "    # port         = 30969\n",
    "    # user         = 'ibmlhapikey'\n",
    "    # key          = 'Xndw8q4VKrLoqM2SB_zwbEuqfyH-9d2zwCyaKFIsEElF'\n",
    "    # connections.connect(         \n",
    "    #     host=host, \n",
    "    #     port=port,\n",
    "    #     user=user,\n",
    "    #     password=key,\n",
    "    #     secure=True,\n",
    "    # )\n",
    "    \n",
    "    print(f\"\\nList connections:\")\n",
    "    print(connections.list_connections())\n",
    "\n",
    "    \n",
    "def load_fits_file(file_path) :\n",
    "    \n",
    "    with fits.open(file_path) as hdul:\n",
    "   \n",
    "        image_data = hdul[0].data\n",
    "        image_resized = resize(image_data, (166, 100), mode='reflect')\n",
    "\n",
    "    return (image_resized ) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_embedding(image_data) : \n",
    "    \n",
    "    embedding = image_data.flatten()\n",
    "    embedding = embedding / np.linalg.norm(embedding)  # Normalizing the embedding\n",
    "    \n",
    "    return embedding\n",
    "    \n",
    "def search_image(search_collection, kafka_data) :\n",
    "\n",
    "    file_contents = base64.b64decode(kafka_data)\n",
    "    fits_file = io.BytesIO(file_contents)\n",
    "    with fits.open(fits_file) as hdul:\n",
    "        hdul.info()\n",
    "        image_data = hdul[0].data\n",
    "\n",
    "    image_resized = resize(image_data, (166, 100), mode='reflect')\n",
    "\n",
    "    embedding_vector = generate_embedding(image_resized)\n",
    "    query_embedding = [embedding_vector]\n",
    "    search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 1000}}\n",
    "    search_collection.load()\n",
    "    results = search_collection.search(\n",
    "        data=query_embedding,\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        limit=3,\n",
    "        output_fields=[\"id\", \"file_path\"],  \n",
    "        expr=None\n",
    "    )\n",
    "\n",
    "    for result in results[0]:\n",
    "        print(f\"Image ID: {result.id}, Image File: {result.file_path}, Difference: {result.distance:.2%}\")\n",
    "\n",
    "\n",
    "def connect_to_watsonxdata() :\n",
    "\n",
    "    # Connection Parameters\n",
    "    userid     = 'ibmlhadmin'\n",
    "    password   = 'password'\n",
    "    hostname   = 'watsonxdata'\n",
    "    port       = '8443'\n",
    "    catalog    = 'tpch'\n",
    "    schema     = 'tiny'\n",
    "    certfile   = \"/certs/lh-ssl-ts.crt\"\n",
    "\n",
    "    # Connect Statement\n",
    "    try:\n",
    "        wxdconnection = prestodb.dbapi.connect(\n",
    "                host=hostname,\n",
    "                port=port,\n",
    "                user=userid,\n",
    "                catalog=catalog,\n",
    "                schema=schema,\n",
    "                http_scheme='https',\n",
    "                auth=prestodb.auth.BasicAuthentication(userid, password)\n",
    "        )\n",
    "        if (certfile != None):\n",
    "            wxdconnection._http_session.verify = certfile\n",
    "        cursor = wxdconnection.cursor()\n",
    "        print(\"Connection successful\")\n",
    "        return wxdconnection\n",
    "    except Exception as e:\n",
    "        print(\"Unable to connect to the database.\")\n",
    "        print(repr(e))\n",
    "\n",
    "def get_images_from_watsonxdata(wxdconnection) :\n",
    "\n",
    "    sql = '''\n",
    "    SELECT json_extract_scalar(_message, '$.image_data') AS \"image_data\" \n",
    "    FROM \"kafka\".\"default\".\"fits-images\" \n",
    "    LIMIT 100 \n",
    "    '''\n",
    "    try:\n",
    "        df = pd.read_sql(sql,wxdconnection)\n",
    "        if (len(df) == 0):\n",
    "            print(\"No rows found.\")\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_to_milvus()\n",
    "fits_coll = Collection(\"image_embeddings\")\n",
    "\n",
    "wxdconnection = connect_to_watsonxdata()\n",
    "data_images = get_images_from_watsonxdata(wxdconnection)\n",
    "\n",
    "for index, row in data_images.iterrows():\n",
    "    search_image(fits_coll,row['image_data'])\n",
    "\n",
    "\n",
    "connections.disconnect(alias=\"default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
